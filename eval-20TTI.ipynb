{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Outlier Method of Filtering\n",
    "\n",
    "**Mostafa Kamal Mostafa Kamel (mos.kamal@nu.edu.eg)**\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eval\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from seasalt.seasalt import apply_salt_pepper\n",
    "from PIL import Image\n",
    "from glob import glob\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from typing import Callable, Optional\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from rich.progress import Progress\n",
    "\n",
    "from scipy.signal import medfilt\n",
    "import warnings\n",
    "import seaborn as sns\n",
    "# from seasalt.fast_seasalt import fixed_window_outlier_filter\n",
    "from seasalt.cython_seasalt import fixed_window_outlier_filter\n",
    "from skimage.metrics import structural_similarity, peak_signal_noise_ratio\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "path_to_images = Path().resolve().joinpath(\"standard-images\")\n",
    "image_paths = glob(f\"{str(path_to_images)}/*\")\n",
    "\n",
    "\n",
    "def plot_transformation_hist_eq(\n",
    "    im, sp_ratio, size=3, max_size=15, metric=\"PSNR\", save_path: Optional[str] = None\n",
    ") -> float:\n",
    "    metric_calculator = peak_signal_noise_ratio if metric==\"PSNR\" else structural_similarity\n",
    "    im_gs = im.convert(\"L\")\n",
    "    arr = np.array(im_gs)  # convert the PIL image object to array\n",
    "    seasoned_image = apply_salt_pepper(arr, ratio=sp_ratio)\n",
    "    corrected_novel = fixed_window_outlier_filter(np.copy(seasoned_image), size)\n",
    "    noisy_metric = metric_calculator(arr, seasoned_image)\n",
    "    novel_metric = metric_calculator(arr, corrected_novel)\n",
    "    fig = plt.figure(\n",
    "        figsize=(\n",
    "            12*3,\n",
    "            5*3,\n",
    "        ),\n",
    "        dpi=80,\n",
    "    )\n",
    "    gs = fig.add_gridspec(1, 3, hspace=0.12, wspace=0.08)\n",
    "    axes = gs.subplots(sharex=\"col\", sharey=\"row\")\n",
    "    list(map(lambda ax: ax.set_axis_off(), axes.flatten()))\n",
    "    list(  # type: ignore\n",
    "        map(\n",
    "            lambda input: input[0].set_title(input[1]),\n",
    "            zip(\n",
    "                axes.flatten(),\n",
    "                [\n",
    "                    \"Original\",\n",
    "                    f\"Noisy Image {round(noisy_metric, 2)} dB\",\n",
    "                    \"Novel Approach\\n\" f\"{round(novel_metric, 2)} dB\",\n",
    "                ],\n",
    "            ),\n",
    "        )\n",
    "    )\n",
    "    axes[0].imshow(im_gs, cmap=\"gray\", vmin=0, vmax=255)\n",
    "    axes[1].imshow(seasoned_image, cmap=\"gray\", vmin=0, vmax=255)\n",
    "    axes[2].imshow(corrected_novel, cmap=\"gray\", vmin=0, vmax=255)\n",
    "    if save_path:\n",
    "        plt.axis(\"off\")\n",
    "        Path(f\"./eval/20TTI-test/{metric}/{save_path}\").parent.mkdir(parents=True, exist_ok=True)\n",
    "        fig.savefig(f\"./eval/20TTI-test/{metric}/{save_path}\")\n",
    "        plt.close()\n",
    "    return novel_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_single_image(seasoned_arr):\n",
    "    fig = plt.figure(\n",
    "        figsize=(\n",
    "            10,\n",
    "            20,\n",
    "        ),\n",
    "        dpi=80,\n",
    "    )\n",
    "    gs = fig.add_gridspec(1, 1, hspace=0.12, wspace=0.08)\n",
    "    ax = gs.subplots(sharex=\"col\", sharey=\"row\")\n",
    "    ax.imshow(seasoned_arr, cmap=\"gray\", vmin=0, vmax=255)\n",
    "    ax.set_axis_off()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf9e7918e2064f4487c35dca86f04d69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 17\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[39mfor\u001b[39;00m sp, size \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(\n\u001b[1;32m     13\u001b[0m     [\u001b[39m0.1\u001b[39m, \u001b[39m0.2\u001b[39m, \u001b[39m0.3\u001b[39m, \u001b[39m0.4\u001b[39m, \u001b[39m0.5\u001b[39m, \u001b[39m0.6\u001b[39m, \u001b[39m0.7\u001b[39m, \u001b[39m0.8\u001b[39m, \u001b[39m0.9\u001b[39m, \u001b[39m0.95\u001b[39m],\n\u001b[1;32m     14\u001b[0m     [\u001b[39m3\u001b[39m,   \u001b[39m3\u001b[39m,   \u001b[39m3\u001b[39m,   \u001b[39m5\u001b[39m,   \u001b[39m5\u001b[39m,   \u001b[39m5\u001b[39m,   \u001b[39m7\u001b[39m,   \u001b[39m11\u001b[39m,   \u001b[39m17\u001b[39m,   \u001b[39m19\u001b[39m],\n\u001b[1;32m     15\u001b[0m ):\n\u001b[1;32m     16\u001b[0m     im \u001b[39m=\u001b[39m Image\u001b[39m.\u001b[39mopen(p)\n\u001b[0;32m---> 17\u001b[0m     novel_snr \u001b[39m=\u001b[39m plot_transformation_hist_eq(\n\u001b[1;32m     18\u001b[0m         im,\n\u001b[1;32m     19\u001b[0m         sp_ratio\u001b[39m=\u001b[39;49msp,\n\u001b[1;32m     20\u001b[0m         size\u001b[39m=\u001b[39;49msize,\n\u001b[1;32m     21\u001b[0m         metric\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mPSNR\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m     22\u001b[0m         save_path\u001b[39m=\u001b[39;49m\u001b[39mf\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m{\u001b[39;49;00mp\u001b[39m.\u001b[39;49msplit(\u001b[39m'\u001b[39;49m\u001b[39m/\u001b[39;49m\u001b[39m'\u001b[39;49m)[\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m]\u001b[39m.\u001b[39;49msplit(\u001b[39m'\u001b[39;49m\u001b[39m.\u001b[39;49m\u001b[39m'\u001b[39;49m)[\u001b[39m0\u001b[39;49m]\u001b[39m}\u001b[39;49;00m\u001b[39m/\u001b[39;49m\u001b[39m{\u001b[39;49;00m\u001b[39mint\u001b[39;49m(sp\u001b[39m*\u001b[39;49m\u001b[39m100\u001b[39;49m)\u001b[39m}\u001b[39;49;00m\u001b[39m.png\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m     23\u001b[0m     )\n\u001b[1;32m     24\u001b[0m     data_dict_eq[\u001b[39m\"\u001b[39m\u001b[39mim_index\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mappend(img_name)\n\u001b[1;32m     25\u001b[0m     data_dict_eq[\u001b[39m\"\u001b[39m\u001b[39msp\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mappend(sp)\n",
      "Cell \u001b[0;32mIn[1], line 32\u001b[0m, in \u001b[0;36mplot_transformation_hist_eq\u001b[0;34m(im, sp_ratio, size, max_size, metric, save_path)\u001b[0m\n\u001b[1;32m     30\u001b[0m arr \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(im_gs)  \u001b[39m# convert the PIL image object to array\u001b[39;00m\n\u001b[1;32m     31\u001b[0m seasoned_image \u001b[39m=\u001b[39m apply_salt_pepper(arr, ratio\u001b[39m=\u001b[39msp_ratio)\n\u001b[0;32m---> 32\u001b[0m corrected_novel \u001b[39m=\u001b[39m fixed_window_outlier_filter(np\u001b[39m.\u001b[39;49mcopy(seasoned_image), size)\n\u001b[1;32m     33\u001b[0m noisy_metric \u001b[39m=\u001b[39m metric_calculator(arr, seasoned_image)\n\u001b[1;32m     34\u001b[0m novel_metric \u001b[39m=\u001b[39m metric_calculator(arr, corrected_novel)\n",
      "File \u001b[0;32m~/Documents/school/project/seasalt/cython_seasalt.pyx:84\u001b[0m, in \u001b[0;36mseasalt.cython_seasalt.fixed_window_outlier_filter\u001b[0;34m()\u001b[0m\n\u001b[1;32m     82\u001b[0m \n\u001b[1;32m     83\u001b[0m \n\u001b[0;32m---> 84\u001b[0m cpdef cnp.ndarray[cnp.uint8_t, ndim=2] fixed_window_outlier_filter(\n\u001b[1;32m     85\u001b[0m         cnp.ndarray[cnp.uint8_t, ndim=2] arr,\n\u001b[1;32m     86\u001b[0m         int size=3,\n",
      "File \u001b[0;32m~/Documents/school/project/seasalt/cython_seasalt.pyx:101\u001b[0m, in \u001b[0;36mseasalt.cython_seasalt.fixed_window_outlier_filter\u001b[0;34m()\u001b[0m\n\u001b[1;32m     99\u001b[0m \n\u001b[1;32m    100\u001b[0m     for index in np.argwhere(arr + 1 < threshold):\n\u001b[0;32m--> 101\u001b[0m         result[index[0], index[1]] = weighted_mean(padded_arr[\n\u001b[1;32m    102\u001b[0m             index[0] - size + 2 * kernel_center + 1 : index[0] + size,\n\u001b[1;32m    103\u001b[0m             index[1] - size + 2 * kernel_center + 1 : index[1] + size,\n",
      "File \u001b[0;32m~/Documents/school/project/seasalt/cython_seasalt.pyx:46\u001b[0m, in \u001b[0;36mseasalt.cython_seasalt.weighted_mean\u001b[0;34m()\u001b[0m\n\u001b[1;32m     44\u001b[0m cdef cnp.ndarray[cnp.uint8_t, ndim=2, cast=True] selector = kernel + 1 > threshold\n\u001b[1;32m     45\u001b[0m \n\u001b[0;32m---> 46\u001b[0m cdef cnp.ndarray[long, ndim=2] ixs = np.transpose(np.where(kernel + 1 > threshold))\n\u001b[1;32m     47\u001b[0m cdef int num_ixs = ixs.shape[0]\n\u001b[1;32m     48\u001b[0m if num_ixs == 0:\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/project-yKDSMzKm-py3.11/lib/python3.11/site-packages/numpy/core/multiarray.py:346\u001b[0m, in \u001b[0;36mwhere\u001b[0;34m(condition, x, y)\u001b[0m\n\u001b[1;32m    256\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    257\u001b[0m \u001b[39m    inner(a, b, /)\u001b[39;00m\n\u001b[1;32m    258\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    341\u001b[0m \n\u001b[1;32m    342\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m    343\u001b[0m     \u001b[39mreturn\u001b[39;00m (a, b)\n\u001b[0;32m--> 346\u001b[0m \u001b[39m@array_function_from_c_func_and_dispatcher\u001b[39m(_multiarray_umath\u001b[39m.\u001b[39mwhere)\n\u001b[1;32m    347\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwhere\u001b[39m(condition, x\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, y\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    348\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    349\u001b[0m \u001b[39m    where(condition, [x, y], /)\u001b[39;00m\n\u001b[1;32m    350\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    416\u001b[0m \u001b[39m           [ 0,  3, -1]])\u001b[39;00m\n\u001b[1;32m    417\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m    418\u001b[0m     \u001b[39mreturn\u001b[39;00m (condition, x, y)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "data_dict_eq = dict(\n",
    "    im_index=[],\n",
    "    sp=[],\n",
    "    novel_snr=[],\n",
    ")\n",
    "root_path = Path().resolve().joinpath(\"aof_eval\").joinpath(\"eq\")\n",
    "\n",
    "with Progress() as progress:\n",
    "    task = progress.add_task(\"Running...\", total=len(image_paths) * 10)\n",
    "    for p in image_paths:\n",
    "        img_name = p.split(\"/\")[-1].split(\".\")[0]\n",
    "        for sp, size in zip(\n",
    "            [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 0.95],\n",
    "            [3,   3,   3,   5,   5,   5,   7,   11,   17,   19],\n",
    "        ):\n",
    "            im = Image.open(p)\n",
    "            novel_snr = plot_transformation_hist_eq(\n",
    "                im,\n",
    "                sp_ratio=sp,\n",
    "                size=size,\n",
    "                metric=\"PSNR\",\n",
    "                save_path=f\"{p.split('/')[-1].split('.')[0]}/{int(sp*100)}.png\",\n",
    "            )\n",
    "            data_dict_eq[\"im_index\"].append(img_name)\n",
    "            data_dict_eq[\"sp\"].append(sp)\n",
    "            data_dict_eq[\"novel_snr\"].append(novel_snr)\n",
    "            progress.update(task, advance=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_theme()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eq = pd.DataFrame(data_dict_eq)\n",
    "df_eq.to_pickle(\"df_eq_20TTI_PSNR.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eq.to_excel(\"x.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eq.im_index.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eq[df_eq.im_index==\"lena\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eq[df_eq.im_index==\"peppers\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eq[df_eq.im_index==\"lake\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eq[df_eq.im_index==\"woman_darkhair\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_aof_agg = df_eq.groupby(\"sp\").agg(\n",
    "    {\n",
    "        \"novel_snr\": [np.mean],\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_aof_agg = df_aof_agg.reset_index()\n",
    "df_aof_agg.columns = [\n",
    "    \"sp\",\n",
    "    \"mean_novel_snr\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_aof_agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_melted = df_aof_agg.melt(id_vars=\"sp\", var_name=\"variable\", value_name=\"value\")\n",
    "df_melted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "sns.lineplot(\n",
    "    data=df_melted[\n",
    "        df_melted.variable.isin(\n",
    "            [\n",
    "                \"mean_novel_snr\",\n",
    "            ]\n",
    "        )\n",
    "    ],\n",
    "    x=\"sp\",\n",
    "    y=\"value\",\n",
    "    hue=\"variable\",\n",
    ")\n",
    "\n",
    "plt.xlabel(\"Salt and Pepper Ratio\")\n",
    "plt.ylabel(\"SNR\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.11 ('image-processing-GAdYTA0i-py3.9')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b9f7d242fac97db32ddc8d7823cd18dd3aca5736246424ff7d0a31879498194b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
